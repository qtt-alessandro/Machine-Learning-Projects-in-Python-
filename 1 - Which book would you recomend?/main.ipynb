{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from scipy import spatial\n",
    "import spacy\n",
    "import collections\n",
    "import heapq\n",
    "from IPython.display import HTML\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "import webbrowser\n",
    "from langdetect import detect\n",
    "from multiprocessing import Pool\n",
    "#import multi_processing_functions\n",
    "import dask.dataframe as ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juanm\\Anaconda3\\envs\\data_science_general\\lib\\site-packages\\distributed\\dashboard\\core.py:79: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:61152</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:61155/status' target='_blank'>http://127.0.0.1:61155/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>8.50 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:61152' processes=4 threads=4, memory=8.50 GB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Useful Functions (read, write, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define a few basic functions that will be used throughout the whole notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def write_file(filename, content):\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    with open(filename, \"w\", encoding='utf-8' ) as f:\n",
    "        f.write(str(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def write_tsv(filename, content):\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    with open(filename, \"wt\", newline='', encoding='utf-8' ) as out_file:\n",
    "        tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "        tsv_writer.writerow(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def read_tsv(filename, type_='utf-8'):\n",
    "    # cp850\n",
    "    with open(filename, encoding = type_) as tsvfile:\n",
    "        reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "        for data in reader:\n",
    "            return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def write_json(file_name, content):\n",
    "    os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
    "    with open(file_name, 'w') as outfile:\n",
    "        json.dump(content, outfile, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def jsonKeys2int(x):\n",
    "    if isinstance(x, dict):\n",
    "            return {int(k):v for k,v in x.items()}\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def read_json(file_name):\n",
    "    with open(file_name) as json_file:\n",
    "        data_dict = json.load(json_file, object_hook=jsonKeys2int)\n",
    "        return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def read_json_simple(file_name):\n",
    "    with open(file_name) as json_file:\n",
    "        data_dict = json.load(json_file)\n",
    "        return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def tsv_files_to_df(path, destiny='data/tsv_files/tsv_files.tsv'):\n",
    "    \"\"\"  \n",
    "    Convert all tsv files in the given path into a dataframe, which will also be saved as a .tsv file\n",
    "    \"\"\"\n",
    "    tsv_files = os.listdir(path)\n",
    "    list_tsv = []\n",
    "    for filename in tsv_files:\n",
    "        d_id = int(re.findall(r'\\d+', filename)[0])\n",
    "        filename = path + filename\n",
    "        book_data = read_tsv(filename)\n",
    "        book_data.insert(0,d_id)\n",
    "        list_tsv.append(book_data)\n",
    "    df = pd.DataFrame(list_tsv)\n",
    "        \n",
    "    df.to_csv(destiny, sep='\\t')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Get the list of books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Getting latest mozilla release info for v0.28.0\n",
      "[WDM] - Trying to download new driver from https://github.com/mozilla/geckodriver/releases/download/v0.28.0/geckodriver-v0.28.0-win64.zip\n",
      "[WDM] - Driver has been saved in cache [C:\\Users\\ADMIN\\.wdm\\drivers\\geckodriver\\win64\\v0.28.0]\n"
     ]
    }
   ],
   "source": [
    "# Initalize web browser for crawling\n",
    "driver = webdriver.Firefox(executable_path=GeckoDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_urls(href):\n",
    "    \"\"\"\n",
    "    Given a specific url (href) crawl through the different list items and return the page url\n",
    "    \"\"\"\n",
    "    driver.get(href)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    page_soup = BeautifulSoup(driver.page_source, features=\"lxml\")\n",
    "    links = page_soup.find_all('a',{'class': 'bookTitle'}, itemprop=\"url\")\n",
    "    \n",
    "    urls = []\n",
    "    # Loop over all links in the href page\n",
    "    for link in links:\n",
    "        url = link.get('href')\n",
    "        url = 'https://www.goodreads.com' + url\n",
    "        urls.append(url)\n",
    "    \n",
    "    urls = '\\n'.join(urls)+'\\n'\n",
    "    \n",
    "    return urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply previous function over all books that we are interested in downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.goodreads.com/list/show/1.Best_Books_Ever?page='\n",
    "path = 'data/book_urls.txt'\n",
    "\n",
    "urls = ''\n",
    "\n",
    "for i in range(0,30000):\n",
    "    href = url+str(i+1)\n",
    "    urls += crawl_urls(href)\n",
    "\n",
    "write_file(path, urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Crawl books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a set of links (generated by the previous function) download their html individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_book(href):\n",
    "    driver.get(href)       \n",
    "    time.sleep(5)\n",
    "    return driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/book_urls.txt'\n",
    "\n",
    "book_urls = open(filename, 'r')\n",
    "for url in book_urls:\n",
    "    page_number = int((count-1)/100)+1\n",
    "    html = scrap_book(url)\n",
    "    path = 'data/page_'+str(page_number)+'/article_'+str(count)+'.html'\n",
    "    write_file(path, html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Parse downloaded pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given all the downloaded htmls, parse them individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    \"\"\"Remove html tags from a string\"\"\"\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html_in_folder(path):\n",
    "    for html_file in os.listdir(path):\n",
    "        print(html_file)\n",
    "        if os.path.exists('data/final_tsv_files/' + re.findall(r'\\d+', html_file)[0] + '.tsv'):\n",
    "            print('not parsed')\n",
    "            continue\n",
    "        else:\n",
    "            with open(path + '/' + html_file, encoding='utf8') as infile:\n",
    "                print('parsing...')\n",
    "                soup = BeautifulSoup(infile, features=\"lxml\")\n",
    "                try:\n",
    "                    Plot = ' '.join([remove_html_tags(str(c)) for c in soup.find_all('div', id=\"description\")[0].contents[3].contents ])\n",
    "                except Exception:\n",
    "                    if not soup.find_all('div', id=\"description\"):\n",
    "                        Plot = ''\n",
    "                    else:\n",
    "                        Plot = ' '.join([remove_html_tags(str(c)) for c in soup.find_all('div', id=\"description\")[0].contents[1].contents ])\n",
    "                if Plot:\n",
    "                    if detect(Plot) != 'en':\n",
    "                        print('Article removed:', html_file)\n",
    "                        continue\n",
    "                try:\n",
    "                    bookTitle = soup.find_all('h1')[0].contents[0].replace('\\n', '').strip()\n",
    "                except:\n",
    "                    print('Wrong html file')\n",
    "                    continue\n",
    "                bookSeries = soup.find_all('h2', id='bookSeries')[0].text.replace('\\n', '').strip()\n",
    "                bookAuthors = ', '.join([soup.find_all('span', itemprop='name')[i].contents[0] for i in range(\n",
    "                    len(soup.find_all('span', itemprop='name')))])\n",
    "                ratingValue = soup.find_all('span', itemprop='ratingValue')[0].contents[0].replace('\\n', '').strip()\n",
    "                ratingCount = soup.find_all('meta', itemprop=\"ratingCount\")[0]['content']\n",
    "                reviewCount = soup.find_all('meta', itemprop=\"reviewCount\")[0]['content']\n",
    "                try:\n",
    "                    NumberofPages = re.findall(r'\\d+', soup.find_all('span', itemprop=\"numberOfPages\")[0].contents[0])[0]\n",
    "                except:\n",
    "                    if not soup.find_all('span', itemprop=\"bookFormat\"):\n",
    "                        NumberofPages = ''\n",
    "                    else:\n",
    "                        NumberofPages = 0\n",
    "                try:\n",
    "                    temp_date = soup.find_all('div', id='details')[0].find_all('div', {\"class\": \"row\"})[1].text.split('\\n')[\n",
    "                        2].split()\n",
    "                    if not temp_date:\n",
    "                        temp_date = soup.find_all('div', id='details')[0].find_all('nobr', {\"class\": \"greyText\"})[0].contents[0].split('\\n')[1].split()[-3:]\n",
    "                except:\n",
    "                    try:\n",
    "                        temp_date = soup.find_all('div', id='details')[0].find_all('div', {\"class\": \"row\"})[0].contents[0].split('\\n')[\n",
    "                            2].split()\n",
    "                    except:\n",
    "                        temp_date = ''\n",
    "                PublishingDate = ' '.join(temp_date)\n",
    "                characters = []\n",
    "                settings = []\n",
    "                for i in range(1, len(soup.find_all('div', id=\"bookDataBox\")[0].find_all('a'))):\n",
    "                    if re.match(r'/characters/', soup.find_all('div', id=\"bookDataBox\")[0].find_all('a')[i].attrs['href']):\n",
    "                        characters.append(soup.find_all('div', id=\"bookDataBox\")[0].find_all('a')[i].text)\n",
    "                    elif re.match(r'/places/', soup.find_all('div', id=\"bookDataBox\")[0].find_all('a')[i].attrs['href']):\n",
    "                        settings.append(soup.find_all('div', id=\"bookDataBox\")[0].find_all('a')[i].text)\n",
    "                characters = ', '.join(characters)\n",
    "                settings = ', '.join(settings)\n",
    "                url = soup.find_all('link', rel='canonical')[0].attrs['href']\n",
    "\n",
    "                final_list = [bookTitle, bookSeries, bookAuthors, ratingValue, ratingCount, reviewCount,\n",
    "                              Plot, NumberofPages, PublishingDate, characters, settings, url]\n",
    "\n",
    "                filename = 'data/final_tsv_files/' + re.findall(r'\\d+', html_file)[0] + '.tsv'\n",
    "\n",
    "                write_tsv(filename, final_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply function over all folders containing the downloaded html files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# None parallel approach\n",
    "for i in range(0,301):\n",
    "    print(i)\n",
    "    parse_html_in_folder('../data_html/page_' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel approach\n",
    "if __name__ == '__main__':\n",
    "    with Pool(8) as p:\n",
    "        print(p.map(multi_processing_functions.parse_html_in_folder, \n",
    "                    ['../data_html/' + i for i in os.listdir('../data_html')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_files_to_df(path='data/final_tsv_files/', destiny='data/tsv_files/final_tsv_files.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dirty.to_csv('data/tsv_files/final_tsv_files.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0. Pre-process of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "stopwords = set(stopwords.words('english'))\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def remove_stop_words(text):\n",
    "    \"\"\"\n",
    "    This allow us to identify stop word in english and remove them. We are also removing character with single length (e.g. \"s\")\n",
    "    \"\"\"    \n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_sentence = [w.lower() for w in word_tokens if w.lower() not in stopwords and not(len(w) == 1 and w.isalpha())]\n",
    "\n",
    "    text = ' '.join(filtered_sentence)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def remove_punctuation(text): \n",
    "    \"\"\"\n",
    "    Remove puntuation from input string\n",
    "    \"\"\"\n",
    "    text = tokenizer.tokenize(text)\n",
    "    clean_punctuation = ' '.join(text)\n",
    "    return clean_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def remove_stemming(text):\n",
    "    \"\"\"\n",
    "    Apply stemming procedure over input text\n",
    "    \"\"\"\n",
    "    ps = PorterStemmer()\n",
    "    words = word_tokenize(text)\n",
    "    stem_sentence=[]\n",
    "    \n",
    "    for w in words:\n",
    "        stem_sentence.append(ps.stem(w))\n",
    "\n",
    "    text = \" \".join(stem_sentence)\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def remove_lemma(text):\n",
    "    \"\"\"\n",
    "    Apply lemmanization procedure over input text\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    lemma = []\n",
    "    for token in doc:\n",
    "        lemma.append(token.lemma_)\n",
    "    text = ' '.join(lemma)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def parse_pulishing_date(publishingDate):\n",
    "    \"\"\"\n",
    "    Only keep last 4 digits of publishing Date (Year of publication)\n",
    "    \"\"\"\n",
    "    return publishingDate[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def global_pre_process(text):\n",
    "    \"\"\" \n",
    "    Function to process everything at once \n",
    "    \"\"\"\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_stop_words(text)\n",
    "    text = remove_lemma(text)\n",
    "    # This makes sure that we also remove strange letters that have not been removed with the previous packages \n",
    "    # (e.g. arabic letters)\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def clean_text(df):\n",
    "    \"\"\"\n",
    "    Take in a Dataframe, and clean based on the previously defined functions (each column is cleaned individually)\n",
    "    \"\"\"\n",
    "    df['BookTitle'] = df.BookTitle.map(global_pre_process)\n",
    "    df['BookSeries'] = df.BookSeries.map(global_pre_process)\n",
    "    df['BookAuthors'] = df.BookAuthors.map(global_pre_process)\n",
    "    df['Plot'] = df.Plot.map(global_pre_process)\n",
    "    df['Characters'] = df.Characters.map(global_pre_process)\n",
    "    df['PublishingDate'] = df.PublishingDate.map(parse_pulishing_date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data frame which still has not been pre-processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "df_dirty = pd.read_csv('data/tsv_files/final_tsv_files.tsv', sep='\\t', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BookID</th>\n",
       "      <th>BookTitle</th>\n",
       "      <th>BookSeries</th>\n",
       "      <th>BookAuthors</th>\n",
       "      <th>RatingValue</th>\n",
       "      <th>RatingCount</th>\n",
       "      <th>ReviewCount</th>\n",
       "      <th>Plot</th>\n",
       "      <th>NumberofPages</th>\n",
       "      <th>PublishingDate</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Settings</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>(The Hunger Games #1)</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6409198</td>\n",
       "      <td>172562</td>\n",
       "      <td>Could you survive on your own in the wild, wit...</td>\n",
       "      <td>374</td>\n",
       "      <td>September 14th 2008</td>\n",
       "      <td>Katniss Everdeen, Peeta Mellark, Cato (Hunger ...</td>\n",
       "      <td>District 12, Panem, Capitol, Panem, Panem</td>\n",
       "      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>The Fault in Our Stars</td>\n",
       "      <td></td>\n",
       "      <td>John Green</td>\n",
       "      <td>4.20</td>\n",
       "      <td>3572895</td>\n",
       "      <td>155821</td>\n",
       "      <td>Despite the tumor-shrinking medical miracle th...</td>\n",
       "      <td>313</td>\n",
       "      <td>January 10th 2012</td>\n",
       "      <td>Augustus Waters, Isaac</td>\n",
       "      <td>Indianapolis, Indiana, Amsterdam</td>\n",
       "      <td>https://www.goodreads.com/book/show/11870085-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>A Prayer for Owen Meany</td>\n",
       "      <td></td>\n",
       "      <td>John Irving</td>\n",
       "      <td>4.23</td>\n",
       "      <td>286642</td>\n",
       "      <td>13845</td>\n",
       "      <td>Eleven-year-old Owen Meany, playing in a Littl...</td>\n",
       "      <td>637</td>\n",
       "      <td>1990</td>\n",
       "      <td>John Wheelwright</td>\n",
       "      <td>Gravesend, New Hampshire, Toronto, Ontario</td>\n",
       "      <td>https://www.goodreads.com/book/show/4473.A_Pra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>Helter Skelter: The True Story of the Manson M...</td>\n",
       "      <td></td>\n",
       "      <td>Vincent Bugliosi, Curt Gentry</td>\n",
       "      <td>4.04</td>\n",
       "      <td>126139</td>\n",
       "      <td>4019</td>\n",
       "      <td>Prosecuting attorney in the Manson trial, Vinc...</td>\n",
       "      <td>689</td>\n",
       "      <td>December 17th 2001</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.goodreads.com/book/show/105992.Hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10000</td>\n",
       "      <td>Henry and June: From \"A Journal of Love\": The ...</td>\n",
       "      <td>(From \"A Journal of Love\" #1)</td>\n",
       "      <td>Anaïs Nin</td>\n",
       "      <td>3.89</td>\n",
       "      <td>10581</td>\n",
       "      <td>624</td>\n",
       "      <td>Taken from the original, uncensored journals o...</td>\n",
       "      <td>304</td>\n",
       "      <td>October 29th 1990</td>\n",
       "      <td>Henry Miller, Anaïs Nin</td>\n",
       "      <td>Paris</td>\n",
       "      <td>https://www.goodreads.com/book/show/11038.Henr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BookID                                          BookTitle  \\\n",
       "0       1                                   The Hunger Games   \n",
       "1      10                             The Fault in Our Stars   \n",
       "2     100                            A Prayer for Owen Meany   \n",
       "3    1000  Helter Skelter: The True Story of the Manson M...   \n",
       "4   10000  Henry and June: From \"A Journal of Love\": The ...   \n",
       "\n",
       "                      BookSeries                    BookAuthors  RatingValue  \\\n",
       "0          (The Hunger Games #1)                Suzanne Collins         4.33   \n",
       "1                                                    John Green         4.20   \n",
       "2                                                   John Irving         4.23   \n",
       "3                                 Vincent Bugliosi, Curt Gentry         4.04   \n",
       "4  (From \"A Journal of Love\" #1)                      Anaïs Nin         3.89   \n",
       "\n",
       "   RatingCount  ReviewCount  \\\n",
       "0      6409198       172562   \n",
       "1      3572895       155821   \n",
       "2       286642        13845   \n",
       "3       126139         4019   \n",
       "4        10581          624   \n",
       "\n",
       "                                                Plot NumberofPages  \\\n",
       "0  Could you survive on your own in the wild, wit...           374   \n",
       "1  Despite the tumor-shrinking medical miracle th...           313   \n",
       "2  Eleven-year-old Owen Meany, playing in a Littl...           637   \n",
       "3  Prosecuting attorney in the Manson trial, Vinc...           689   \n",
       "4  Taken from the original, uncensored journals o...           304   \n",
       "\n",
       "        PublishingDate                                         Characters  \\\n",
       "0  September 14th 2008  Katniss Everdeen, Peeta Mellark, Cato (Hunger ...   \n",
       "1    January 10th 2012                             Augustus Waters, Isaac   \n",
       "2                 1990                                   John Wheelwright   \n",
       "3   December 17th 2001                                                      \n",
       "4    October 29th 1990                            Henry Miller, Anaïs Nin   \n",
       "\n",
       "                                     Settings  \\\n",
       "0   District 12, Panem, Capitol, Panem, Panem   \n",
       "1            Indianapolis, Indiana, Amsterdam   \n",
       "2  Gravesend, New Hampshire, Toronto, Ontario   \n",
       "3                                               \n",
       "4                                       Paris   \n",
       "\n",
       "                                                 Url  \n",
       "0  https://www.goodreads.com/book/show/2767052-th...  \n",
       "1  https://www.goodreads.com/book/show/11870085-t...  \n",
       "2  https://www.goodreads.com/book/show/4473.A_Pra...  \n",
       "3  https://www.goodreads.com/book/show/105992.Hel...  \n",
       "4  https://www.goodreads.com/book/show/11038.Henr...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dirty.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply clean_text function over the \"dirty\" dataframe using dask to optimize running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_dataframe = ddf.from_pandas(df_dirty, npartitions=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_clean = dask_dataframe.map_partitions(clean_text, meta=df_dirty).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BookID</th>\n",
       "      <th>BookTitle</th>\n",
       "      <th>BookSeries</th>\n",
       "      <th>BookAuthors</th>\n",
       "      <th>RatingValue</th>\n",
       "      <th>RatingCount</th>\n",
       "      <th>ReviewCount</th>\n",
       "      <th>Plot</th>\n",
       "      <th>NumberofPages</th>\n",
       "      <th>PublishingDate</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Settings</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>hunger game</td>\n",
       "      <td>hunger game 1</td>\n",
       "      <td>suzanne collins</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6409198</td>\n",
       "      <td>172562</td>\n",
       "      <td>could survive wild every one make sure live se...</td>\n",
       "      <td>374</td>\n",
       "      <td>2008</td>\n",
       "      <td>katniss everdeen peeta mellark cato hunger gam...</td>\n",
       "      <td>District 12, Panem, Capitol, Panem, Panem</td>\n",
       "      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>fault star</td>\n",
       "      <td></td>\n",
       "      <td>john green</td>\n",
       "      <td>4.20</td>\n",
       "      <td>3572895</td>\n",
       "      <td>155821</td>\n",
       "      <td>despite tumor shrink medical miracle buy year ...</td>\n",
       "      <td>313</td>\n",
       "      <td>2012</td>\n",
       "      <td>augustus water isaac</td>\n",
       "      <td>Indianapolis, Indiana, Amsterdam</td>\n",
       "      <td>https://www.goodreads.com/book/show/11870085-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>prayer owen meany</td>\n",
       "      <td></td>\n",
       "      <td>john irving</td>\n",
       "      <td>4.23</td>\n",
       "      <td>286642</td>\n",
       "      <td>13845</td>\n",
       "      <td>eleven year old owen meany play little league ...</td>\n",
       "      <td>637</td>\n",
       "      <td>1990</td>\n",
       "      <td>john wheelwright</td>\n",
       "      <td>Gravesend, New Hampshire, Toronto, Ontario</td>\n",
       "      <td>https://www.goodreads.com/book/show/4473.A_Pra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>helter skelter true story manson murder</td>\n",
       "      <td></td>\n",
       "      <td>vincent bugliosi curt gentry</td>\n",
       "      <td>4.04</td>\n",
       "      <td>126139</td>\n",
       "      <td>4019</td>\n",
       "      <td>prosecute attorney manson trial vincent buglio...</td>\n",
       "      <td>689</td>\n",
       "      <td>2001</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.goodreads.com/book/show/105992.Hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10000</td>\n",
       "      <td>henry june journal love unexpurgate diary ana ...</td>\n",
       "      <td>journal love 1</td>\n",
       "      <td>ana s nin</td>\n",
       "      <td>3.89</td>\n",
       "      <td>10581</td>\n",
       "      <td>624</td>\n",
       "      <td>take original uncensored journal ana s nin hen...</td>\n",
       "      <td>304</td>\n",
       "      <td>1990</td>\n",
       "      <td>henry miller ana s nin</td>\n",
       "      <td>Paris</td>\n",
       "      <td>https://www.goodreads.com/book/show/11038.Henr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27146</td>\n",
       "      <td>9993</td>\n",
       "      <td>catch true story real fake</td>\n",
       "      <td></td>\n",
       "      <td>frank abagnale stan redding</td>\n",
       "      <td>4.05</td>\n",
       "      <td>51450</td>\n",
       "      <td>2478</td>\n",
       "      <td>stole every nickel blow fine thread luxurious ...</td>\n",
       "      <td>224</td>\n",
       "      <td>2003</td>\n",
       "      <td>sean riley</td>\n",
       "      <td></td>\n",
       "      <td>https://www.goodreads.com/book/show/138269.Cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27147</td>\n",
       "      <td>9995</td>\n",
       "      <td>rake</td>\n",
       "      <td>lesson love 1</td>\n",
       "      <td>suzanne enoch</td>\n",
       "      <td>3.86</td>\n",
       "      <td>7694</td>\n",
       "      <td>369</td>\n",
       "      <td>three determined young lady vow give three lon...</td>\n",
       "      <td>375</td>\n",
       "      <td>2002</td>\n",
       "      <td>greydon brakenridge duke wycliffe georgina hal...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.goodreads.com/book/show/823583.The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27148</td>\n",
       "      <td>9996</td>\n",
       "      <td>manfred</td>\n",
       "      <td></td>\n",
       "      <td>lord byron</td>\n",
       "      <td>3.81</td>\n",
       "      <td>1856</td>\n",
       "      <td>109</td>\n",
       "      <td>manfred contain supernatural element keep popu...</td>\n",
       "      <td>84</td>\n",
       "      <td>2009</td>\n",
       "      <td>abbot st maurice manfre manfred herman manfre ...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.goodreads.com/book/show/3730956-ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27149</td>\n",
       "      <td>9997</td>\n",
       "      <td>world representation vol 1</td>\n",
       "      <td>world representation 1</td>\n",
       "      <td>arthur schopenhauer judith norman payne alista...</td>\n",
       "      <td>4.19</td>\n",
       "      <td>8415</td>\n",
       "      <td>192</td>\n",
       "      <td>arthur schopenhauer die welt als wille und vor...</td>\n",
       "      <td>534</td>\n",
       "      <td>1966</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.goodreads.com/book/show/19506.The_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27150</td>\n",
       "      <td>9999</td>\n",
       "      <td>fearless</td>\n",
       "      <td></td>\n",
       "      <td>tim lott</td>\n",
       "      <td>3.83</td>\n",
       "      <td>1227</td>\n",
       "      <td>197</td>\n",
       "      <td>smartly paint exterior city community faith sc...</td>\n",
       "      <td>266</td>\n",
       "      <td>2007</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.goodreads.com/book/show/1206359.Fe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27151 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       BookID                                          BookTitle  \\\n",
       "0           1                                        hunger game   \n",
       "1          10                                         fault star   \n",
       "2         100                                  prayer owen meany   \n",
       "3        1000            helter skelter true story manson murder   \n",
       "4       10000  henry june journal love unexpurgate diary ana ...   \n",
       "...       ...                                                ...   \n",
       "27146    9993                         catch true story real fake   \n",
       "27147    9995                                               rake   \n",
       "27148    9996                                            manfred   \n",
       "27149    9997                         world representation vol 1   \n",
       "27150    9999                                           fearless   \n",
       "\n",
       "                   BookSeries  \\\n",
       "0               hunger game 1   \n",
       "1                               \n",
       "2                               \n",
       "3                               \n",
       "4              journal love 1   \n",
       "...                       ...   \n",
       "27146                           \n",
       "27147           lesson love 1   \n",
       "27148                           \n",
       "27149  world representation 1   \n",
       "27150                           \n",
       "\n",
       "                                             BookAuthors  RatingValue  \\\n",
       "0                                        suzanne collins         4.33   \n",
       "1                                             john green         4.20   \n",
       "2                                            john irving         4.23   \n",
       "3                           vincent bugliosi curt gentry         4.04   \n",
       "4                                              ana s nin         3.89   \n",
       "...                                                  ...          ...   \n",
       "27146                        frank abagnale stan redding         4.05   \n",
       "27147                                      suzanne enoch         3.86   \n",
       "27148                                         lord byron         3.81   \n",
       "27149  arthur schopenhauer judith norman payne alista...         4.19   \n",
       "27150                                           tim lott         3.83   \n",
       "\n",
       "       RatingCount  ReviewCount  \\\n",
       "0          6409198       172562   \n",
       "1          3572895       155821   \n",
       "2           286642        13845   \n",
       "3           126139         4019   \n",
       "4            10581          624   \n",
       "...            ...          ...   \n",
       "27146        51450         2478   \n",
       "27147         7694          369   \n",
       "27148         1856          109   \n",
       "27149         8415          192   \n",
       "27150         1227          197   \n",
       "\n",
       "                                                    Plot NumberofPages  \\\n",
       "0      could survive wild every one make sure live se...           374   \n",
       "1      despite tumor shrink medical miracle buy year ...           313   \n",
       "2      eleven year old owen meany play little league ...           637   \n",
       "3      prosecute attorney manson trial vincent buglio...           689   \n",
       "4      take original uncensored journal ana s nin hen...           304   \n",
       "...                                                  ...           ...   \n",
       "27146  stole every nickel blow fine thread luxurious ...           224   \n",
       "27147  three determined young lady vow give three lon...           375   \n",
       "27148  manfred contain supernatural element keep popu...            84   \n",
       "27149  arthur schopenhauer die welt als wille und vor...           534   \n",
       "27150  smartly paint exterior city community faith sc...           266   \n",
       "\n",
       "      PublishingDate                                         Characters  \\\n",
       "0               2008  katniss everdeen peeta mellark cato hunger gam...   \n",
       "1               2012                               augustus water isaac   \n",
       "2               1990                                   john wheelwright   \n",
       "3               2001                                                      \n",
       "4               1990                             henry miller ana s nin   \n",
       "...              ...                                                ...   \n",
       "27146           2003                                         sean riley   \n",
       "27147           2002  greydon brakenridge duke wycliffe georgina hal...   \n",
       "27148           2009  abbot st maurice manfre manfred herman manfre ...   \n",
       "27149           1966                                                      \n",
       "27150           2007                                                      \n",
       "\n",
       "                                         Settings  \\\n",
       "0       District 12, Panem, Capitol, Panem, Panem   \n",
       "1                Indianapolis, Indiana, Amsterdam   \n",
       "2      Gravesend, New Hampshire, Toronto, Ontario   \n",
       "3                                                   \n",
       "4                                           Paris   \n",
       "...                                           ...   \n",
       "27146                                               \n",
       "27147                                               \n",
       "27148                                               \n",
       "27149                                               \n",
       "27150                                               \n",
       "\n",
       "                                                     Url  \n",
       "0      https://www.goodreads.com/book/show/2767052-th...  \n",
       "1      https://www.goodreads.com/book/show/11870085-t...  \n",
       "2      https://www.goodreads.com/book/show/4473.A_Pra...  \n",
       "3      https://www.goodreads.com/book/show/105992.Hel...  \n",
       "4      https://www.goodreads.com/book/show/11038.Henr...  \n",
       "...                                                  ...  \n",
       "27146  https://www.goodreads.com/book/show/138269.Cat...  \n",
       "27147  https://www.goodreads.com/book/show/823583.The...  \n",
       "27148  https://www.goodreads.com/book/show/3730956-ma...  \n",
       "27149  https://www.goodreads.com/book/show/19506.The_...  \n",
       "27150  https://www.goodreads.com/book/show/1206359.Fe...  \n",
       "\n",
       "[27151 rows x 13 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('data/clean_tsv_files/clean_final.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Conjunctive query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "# Read Clean tsv file\n",
    "df_clean = pd.read_csv('data/clean_tsv_files/clean_final.tsv', sep='\\t', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1. Create your index!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary_inverted_index(df, columns):\n",
    "    \"\"\"\n",
    "    This function returns a dictionary with all the words in the dataframe (and specifically the provided columns) \n",
    "    and its inverted index\n",
    "    Example:\n",
    "    vocabulary_dict = {'river': 1, 'game': 2, 'friend': 3, ...}\n",
    "    inverted_index = {1: [1, 4, 7], 2: [3, 6, 9], 3: [2, 7, 8]} where the list contains the documents in which \n",
    "    the word 1 (river) appears in\n",
    "    \n",
    "    df: Clean Dataframe\n",
    "    columns: Columns over which the vocabulary and inverted index dictionaries will be generated\n",
    "    \"\"\"\n",
    "    vocabulary = {}\n",
    "    count = 1\n",
    "    inverted_index = {}\n",
    "    for index, row in df.iterrows():\n",
    "        d_id = row['BookID']\n",
    "        if isinstance(columns, list):\n",
    "            text = (' '.join([row[i] for i in columns])).split(' ')\n",
    "        else:\n",
    "            raise('Column must be a list')\n",
    "            \n",
    "        for word in text:\n",
    "            if word not in vocabulary: \n",
    "                vocabulary[word] = count\n",
    "                inverted_index[count] = [d_id]\n",
    "                count +=1\n",
    "            else:\n",
    "                key = vocabulary[word]\n",
    "                if d_id not in inverted_index[key]:\n",
    "                     inverted_index[key].append(d_id)\n",
    "    return vocabulary, inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 37.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocabulary, inverted_index = get_vocabulary_inverted_index(df_clean, columns=['Plot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save dictionaries as json files for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json('data/inverted_index.json', inverted_index)\n",
    "write_json('data/vocabulary_dict.json', vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2. Execute the query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functionality to get intersection of documents in which query appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def get_pointer_values(pointer, index_list):\n",
    "    \"\"\" Based on a set of pointer values get the documents \"\"\"\n",
    "    values = []\n",
    "    for i in range(len(pointer)):\n",
    "        values.append(index_list[i][pointer[i]])\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def update_pointer(values, pointer):\n",
    "    \"\"\" Given the values, compute the minimum and update the pointer accordingly based on their minimum \"\"\"\n",
    "    mins = np.where(values == np.min(values))[0]\n",
    "    for i in range(0, len(mins)):\n",
    "        pointer[mins[i]] = pointer[mins[i]] + 1 \n",
    "    return pointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def query_function(query, index, vocabulary):\n",
    "    \"\"\" \n",
    "    Given a query find the documents in which these appear based on the index \n",
    "    query: query string\n",
    "    index: inverted index as dictionary\n",
    "    vocabulary: vocabulary dictionary\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Pre-process query \n",
    "    query = global_pre_process(query)\n",
    "    \n",
    "    # Query to list of strings\n",
    "    query_list = query.split()\n",
    "    \n",
    "    # Map strings to integer based on dict\n",
    "    try:\n",
    "        integer_list = [vocabulary[i] for i in query_list]\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "    # Start to look for the intersection of the query in the index\n",
    "    total_query_documents = [sorted(index[i]) for i in integer_list]\n",
    "    \n",
    "    # Generate a list with the pointer values\n",
    "    pointers = np.full(len(total_query_documents), 0)\n",
    "    values = np.full(len(total_query_documents), 0)\n",
    "    \n",
    "    # List where intersection documents will be stored\n",
    "    intersection = []\n",
    "\n",
    "    # Compute the document in which the search should stop\n",
    "    max_list = np.array([max(total_query_documents[i]) for i in range(len(total_query_documents))])\n",
    "\n",
    "    try:\n",
    "        # Loop over all elements stopping at the minimum between all documents\n",
    "        while np.any(values != max_list):\n",
    "            # Get the documents based on the pointer\n",
    "            values = get_pointer_values(pointer = pointers, \n",
    "                                        index_list = total_query_documents)\n",
    "            # If all values are equal we have found a match and all the pointer values are increased by one\n",
    "            if len(set(values)) == 1:\n",
    "                intersection.append(values[0])\n",
    "                pointers += 1\n",
    "            # If all values are not equal increase the values of the minimum pointers\n",
    "            else:\n",
    "                pointers = update_pointer(values, pointers)\n",
    "    except:\n",
    "        intersection = sorted(list(set.intersection(*map(set,total_query_documents))))\n",
    "    \n",
    "    assert intersection == sorted(list(set.intersection(*map(set,total_query_documents)))), 'Algorithm is not returning same result as python implementation'\n",
    "    \n",
    "    return intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def path_to_image_html(path):\n",
    "    return '<img src=\"'+ path + '\" style=max-height:124px;\"/>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def show_results(book_ids, df):\n",
    "    \"\"\"\n",
    "    Get relevant information which will be shown in the final dataframe for the books in book_ids\n",
    "    df: This dataframe should not be pre-processed\n",
    "    book_ids: list of books\n",
    "    \"\"\"\n",
    "    output = df[df['BookID'].isin(book_ids)][['BookTitle', 'Plot', 'Url']]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def search_engine_1(query, inverted_index, vocabulary, df):\n",
    "    \"\"\"\n",
    "    Basic search engine which returns all books with the provided query\n",
    "    query: Query of user\n",
    "    df: This dataframe should not be pre-processed\n",
    "    \"\"\"\n",
    "    query_results = query_function(query, inverted_index, vocabulary)\n",
    "    if len(query_results) == 0:\n",
    "        print('There are no results for the search')\n",
    "    else:\n",
    "        output = show_results(query_results, df)\n",
    "        output = HTML(output.to_html(escape=False,\n",
    "                                     formatters=dict(column_name_with_image_links=path_to_image_html)))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read json files (vocabulary and inverted index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "inverted_index = read_json('data/inverted_index.json')\n",
    "vocabulary = read_json_simple('data/vocabulary_dict.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run First Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "input_query = 'harry potter magic hogwarts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BookTitle</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>Harry Potter and the Goblet of Fire</td>\n",
       "      <td>Harry Potter is midway through his training as a wizard and his coming of age. Harry wants to get away from the pernicious Dursleys and go to the International Quidditch Cup with Hermione, Ron, and the Weasleys. He wants to dream about Cho Chang, his crush (and maybe do more than dream). He wants to find out about the mysterious event that's supposed to take place at Hogwarts this year, an event involving two other rival schools of magic, and a competition that hasn't happened for hundreds of years. He wants to be a normal, fourteen-year-old wizard. But unfortunately for Harry Potter, he's not normal - even by wizarding standards.   And in his case, different can be deadly.</td>\n",
       "      <td>https://www.goodreads.com/book/show/6.Harry_Potter_and_the_Goblet_of_Fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>Harry Potter: A History of Magic</td>\n",
       "      <td>Harry Potter: A History of Magic is the official book of the exhibition, a once-in-a-lifetime collaboration between Bloomsbury, J.K. Rowling and the brilliant curators of the British Library. It promises to take readers on a fascinating journey through the subjects studied at Hogwarts School of Witchcraft and Wizardry – from Alchemy and Potions classes through to Herbology and Care of Magical Creatures.   Each chapter showcases a treasure trove of artefacts from the British Library and other collections around the world, beside exclusive manuscripts, sketches and illustrations from the Harry Potter archive. There's also a specially commissioned essay for each subject area by an expert, writer or cultural commentator, inspired by the contents of the exhibition – absorbing, insightful and unexpected contributions from Steve Backshall, the Reverend Richard Coles, Owen Davies, Julia Eccleshare, Roger Highfield, Steve Kloves, Lucy Mangan, Anna Pavord and Tim Peake, who offer a personal perspective on their magical theme.   Readers will be able to pore over ancient spell books, amazing illuminated scrolls that reveal the secret of the Elixir of Life, vials of dragon's blood, mandrake roots, painted centaurs and a genuine witch's broomstick, in a book that shows J.K. Rowling's magical inventions alongside their cultural and historical forebears.   This is the ultimate gift for Harry Potter fans, curious minds, big imaginations, bibliophiles and readers around the world who missed out on the chance to see the exhibition in person.</td>\n",
       "      <td>https://www.goodreads.com/book/show/35613533-harry-potter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6275</th>\n",
       "      <td>The Harry Potter Collection 1-4</td>\n",
       "      <td>The exciting tales of Harry Potter, the young wizard-in-training, have taken the world by storm, and fans just can't get enough of the magical world of Hogwarts and beyond. If you buy one of the Harry Potter books, we guarantee you'll want the next...and the next...and the next -- so why not have them all, right at your fingertips? With the Harry Potter Hardcover Box Set (Books 1-4), Barnes amp; Noble.com offers simple one-stop shopping for your Harry Potter library! As easy as the wave of a magic wand, you can get all four Harry Potter books delivered to your doorstep at once.p   The Harry Potter Hardcover Box Set (Books 1-4) includes hardcover editions of iHarry Potter and the Sorcerer's Stone, Harry Potter and the Chamber of Secrets, Harry Potter and the Prisoner of Azkaban,/i and iHarry Potter and the Goblet of Fire./i The books come snugly packed in a sturdy cardboard slipcase, beautifully decorated with memorable scenes from the books.p   So buy the set, and not even a pesky Locomotor Mortis spell cast by the evil Lord Voldemor...(oooops, sorry -- He-Who-Must-Not-Be-Named) can get in the way of your enjoying all of the mystery, adventure, intrigue, and, of course, magic that Muggles around the world can't seem to get enough of. Hold on tight -- it's going to be a wild ride!</td>\n",
       "      <td>https://www.goodreads.com/book/show/99298.The_Harry_Potter_Collection_1_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run cell\n",
    "search = search_engine_1(input_query, inverted_index, vocabulary, df_dirty)\n",
    "search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Conjunctive query & Ranking score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1. Inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_tfidf(df, vocabulary, inverted_index, json_name='tfidf.json', columns=['Plot']):\n",
    "    '''\n",
    "    Vecterize Plots\n",
    "    This function, given a vocabulary dictionary, inverted index and pre-processed dataframe return a dictionary with \n",
    "    tfidf scores\n",
    "    Example: {1: {1: 0.7, 5: 3.7}, 2: {3: 1.7, 6: 5.7}} Where 1 and 2 denote the book_id and 1, 5, 3, 6 denote the word.\n",
    "    df: Pre-processed data frame (df_clean)\n",
    "    param column: If a list is provided the score will be computed over several columns\n",
    "    '''\n",
    "\n",
    "    no_of_documents = len(df)\n",
    "    \n",
    "    # number of words in vacabulary\n",
    "    no_of_words_in_vocab = len(vocabulary)\n",
    "    \n",
    "    tfidfDicts = {}\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        d_id = row['BookID']\n",
    "\n",
    "        if isinstance(columns, list):\n",
    "            text = (' '.join([row[i] for i in columns])).split(' ')\n",
    "        else:\n",
    "            raise('Column must be a list')\n",
    "            \n",
    "        no_of_words_in_plot = len(text)\n",
    "        # Create a vector\n",
    "        tfDict = dict.fromkeys((i for i in range(1, no_of_words_in_vocab+1)), 0)\n",
    "        \n",
    "        \n",
    "        for word in text:\n",
    "            index = vocabulary[word]\n",
    "            tfDict[index] +=1\n",
    "        \n",
    "        tfidfDict = {}\n",
    "        \n",
    "        for key, value in tfDict.items():\n",
    "            if value != 0:\n",
    "                \n",
    "                no_of_documents_appeared = len(inverted_index[key])\n",
    "\n",
    "                tfidf = (value/no_of_words_in_plot) * np.log(no_of_documents/no_of_documents_appeared)\n",
    "\n",
    "                tfidfDict[key] = float('{:.4f}'.format(tfidf))\n",
    "                        \n",
    "        tfidfDicts[d_id] = tfidfDict\n",
    "        \n",
    "    documents = collections.OrderedDict(sorted(tfidfDicts.items()))\n",
    "    write_json('data/' + json_name, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Generate tfidf based only on the 'Plot' of the books (vocabulary and inverted index have been generated only over PLot as \n",
    "# well) \n",
    "vectorize_tfidf(df_clean, vocabulary, inverted_index, json_name='tfidf.json', columns=['Plot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def get_cosine(doc, query):\n",
    "    \"\"\"\n",
    "    Given two vectors, return a float which is the cosine similarity score\n",
    "    doc: dictionary vector \n",
    "    query: dictionary vector\n",
    "    \"\"\"\n",
    "    intersection = set(doc.keys()) & set(query.keys())\n",
    "    numerator = sum([doc[x] * query[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([doc[x] ** 2 for x in list(doc.keys())])\n",
    "    sum2 = sum([query[x] ** 2 for x in list(query.keys())])\n",
    "    denominator = np.sqrt(sum1) * np.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def show_results_cosine_similarity(book_id, cosine_similarity, df):\n",
    "    \"\"\"\n",
    "    Generate a tuple with the relevant information about a book that will be displayed in the search engine, \n",
    "    and the cosine similarity score\n",
    "    df: Not pre-processed data set\n",
    "    \"\"\"\n",
    "    data = df[df.BookID == book_id][['BookTitle', 'Plot', 'Url']].values.tolist()[0]\n",
    "    output = (cosine_similarity, data)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def search_engine_2(query, inverted_index, vocabulary, tfidf_scores_dict, df, k = 10):\n",
    "    \"\"\"\n",
    "    Cosine similarity search engine which returns all books with the provided query in order of highest cosine \n",
    "    value, and displaying top k books\n",
    "    \n",
    "    query: Query of user\n",
    "    df: This dataframe should not be pre-processed\n",
    "    \"\"\"\n",
    "    output = pd.DataFrame(columns=['BookTitle', 'Plot', 'Url', 'Similarity'])\n",
    "    documents_with_query_words = query_function(query, inverted_index, vocabulary)\n",
    "    queryed_documents_tfidf = {key: value for key, value in tfidf_scores_dict.items() if key in documents_with_query_words}\n",
    "    heap_data = []\n",
    "    \n",
    "    if len(documents_with_query_words) == 0:\n",
    "        print('There are no results for the search')\n",
    "    else:\n",
    "    \n",
    "        # pre-process query\n",
    "        query = global_pre_process(query)\n",
    "\n",
    "        # vectorize query\n",
    "        vector_query = {}\n",
    "        for word in query.split(' '):\n",
    "            index = vocabulary[word]\n",
    "            vector_query[index] = 1\n",
    "\n",
    "        for i in queryed_documents_tfidf.keys():\n",
    "            similarity = get_cosine(queryed_documents_tfidf[i], vector_query)\n",
    "            x = show_results_cosine_similarity(i, similarity, df)\n",
    "            if len(heap_data) < k:\n",
    "                heapq.heappush(heap_data, x)\n",
    "            else:\n",
    "                heapq.heappushpop(heap_data, x)\n",
    "\n",
    "        for i in range(len(heap_data)):\n",
    "            output = output.append(pd.Series([heap_data[-(i+1)][1][0], heap_data[-(i+1)][1][1], \n",
    "                                              heap_data[-(i+1)][1][2], heap_data[-(i+1)][0]], \n",
    "                                             index=output.columns), ignore_index=True) \n",
    "        output = output.sort_values(by='Similarity', ascending=False)\n",
    "        output = HTML(output.to_html(escape=False,\n",
    "                                     formatters=dict(column_name_with_image_links=path_to_image_html)))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "tfidfDicts = read_json('data/tfidf.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "input_query = 'break heart'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BookTitle</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Against All Odds</td>\n",
       "      <td>Our lives shattered... Our hearts broken... Our souls torn to pieces...   He was my world, my whole life. My reason for breathing. I had a perfect marriage, a baby on the way, and I felt fulfilled—almost invincible.    Until the day life hit, leaving me broken, vulnerable, and alone.   She was my life. My ray of hope on the cloudiest day. With her, I thought I had the ultimate safety. A love that would never hurt or betray me. I gave her my heart, my body, and my soul.    Until she broke me, destroying every dream and illusion I had about life, love, and marriage.   In our grief, we made a mistake. A mistake I'm not sure we can come back from.</td>\n",
       "      <td>https://www.goodreads.com/book/show/18803442-against-all-odds</td>\n",
       "      <td>0.293084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Knight of the Rose</td>\n",
       "      <td>Book no longer in print.    Refer now to the combined Tears of the Broken and The Knight of the Rose as \"Dark Secrets\".   Sequel to the internationally successful vampire novel, Tears of the Broken.   Love was only the beginning of her nightmares.    When Ara discovered the existence of vampires, she was given the choice between a life as one of them, or a life without her true love.   But fate has a funny way of making choices for you.    After breaking the heart of the boy she loves with a truth he cannot bear, Ara will find herself in the arms of a predator who will steal her innocence and force the hand of fate.    Will David Knight become her rescuer once again, or will he be too late?</td>\n",
       "      <td>https://www.goodreads.com/book/show/13570791-the-knight-of-the-rose</td>\n",
       "      <td>0.220297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Almost Broken</td>\n",
       "      <td>Lauren Brooks fell in love with Cal Scott at 21, married him at 22 and had her heart broken at 23 when he walked out of their marriage. At 25, though raising his daughter on her own, Lauren was finally moving on with her life. Until, she learned the reason for Cal's abandonment, the walls she’d carefully built around her collapsed..     The day she meets Chris, all those feelings she thought she had bottled up come spilling out. She can’t afford to give into her heart’s desire again. Love nearly broke her once, and her daughter doesn't need two broken parents.   Christopher Scott is in love, newly engaged to Jenna, who saw him through an illness he didn’t think he could survive. He’s finally settling into the life he’s always wanted, making plans he only dared to dream before now.   Until, a woman named Lauren arrives on his doorstep.   She’s intriguing, beautiful and, try as he might, he can’t stay away. The closer he gets to her, the more his rock-solid plans begin to crumble. All he knows is that Lauren is the missing piece to a puzzle he must solve. For him to put all the pieces in place, he’ll have to follow his heart, and that might cost him everything...</td>\n",
       "      <td>https://www.goodreads.com/book/show/22667507-almost-broken</td>\n",
       "      <td>0.217010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A Love Surrendered</td>\n",
       "      <td>Orphaned in Iowa, Annie Kennedy moves to Boston to stay with her spinster aunt. She longs for romance to fill the void left by her parents' death. But when she falls hard for Steven O'Connor, the man who broke an engagement to her sister, Annie is worried. Will he break her heart too when he discovers who she really is?</td>\n",
       "      <td>https://www.goodreads.com/book/show/13498999-a-love-surrendered</td>\n",
       "      <td>0.216607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Broken for You</td>\n",
       "      <td>National best seller and  Today  show Book Club selection,  Broken for You  is the story of two women in self-imposed exile whose lives are transformed when their paths intersect. Stephanie Kallos's debut novel is a work of infinite charm, wit and heart. It is also a glorious homage to the beauty of broken things.    When we meet septuagenarian Margaret Hughes, she is living alone in a mansion in Seattle with only a massive collection of valuable antiques for company. Enter Wanda Schultz, a young woman with a broken heart who has come west to search for her wayward boyfriend. Both women are guarding dark secrets and have spent many years building up protective armor against the outside world. As their tentative friendship evolves, the armor begins to fall away and Margaret opens her house to the younger woman. This launches a series of unanticipated events, leading Margaret to discover a way to redeem her cursed past, and Wanda to learn the true purpose of her cross-country journey.    Both funny and heartbreaking,  Broken for You  is a testament to the saving graces of surrogate families and shows how far the tiniest repair jobs can go in righting the world's wrongs.</td>\n",
       "      <td>https://www.goodreads.com/book/show/96702.Broken_for_You</td>\n",
       "      <td>0.205746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bittersweet Moments</td>\n",
       "      <td>Can the embers of an old life ignite the flames of a new love?   Six years ago, Melisa Bergfeld’s husband died. As the grief of losing him tore into her, she lost his last gift to her—their unborn child—and her hopes and dreams turned to ashes.   Left with a life she no longer wants, she seeks salvation in a homeless shelter. For a while, that’s more than enough.   But when a fire breaks out, in walks the man who will try to save her life—if she’ll let him.   Florian “Heat” Dane has left behind a trail of broken hearts in his wake, including pieces of his own. For all the girls he’s used to fill the hole in his heart, there has been just one he could never erase from his memories. But when Melisa married his best friend Scott Bergfeld, he knew she would never be his the way she’d been the one unforgettable night they spent together. Now that she’s back in his life, he will do anything to recapture her heart, even if it means giving away his own.   Heat still has the power to ignite passion in Melisa, something she both desires and rejects. He’s a known heartbreaker, and if there is one thing Melisa doesn’t need, it’s another crack in her heart. But when he confesses his love for her, she fears her secrets from the past will surface. And she might be the one to break his heart this time.</td>\n",
       "      <td>https://www.goodreads.com/book/show/20895867-bittersweet-moments</td>\n",
       "      <td>0.193598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My Existence Craves Yours</td>\n",
       "      <td>My Existence Craves Yours is about how one heart seeks out the other in love, as if you’re drought and they’re rain. It’s a story that contains true love, trauma of a broken heart, mental illness, imprisonment of one’s soul and lessons of life.   Amna Dhanani says,  “I went through my work trying to come up with a theme, I wrecked my brain for weeks until I saw a pattern for a story. I’ve arranged the poems in a way that each poem has a place in the flow, even though the order that I’ve made is fictional but I’ve not only felt but lived every word that is in here, some by me and some by others as I couldn’t stop myself from writing what my eyes saw, what my ears heard and what my heart felt through the pain of those around me. It often made my own existence suffer from their grief.   After the story, I’ve shared bits and pieces about my suffering and survival, ending on The Words chapter.”</td>\n",
       "      <td>https://www.goodreads.com/book/show/42356004-my-existence-craves-yours</td>\n",
       "      <td>0.180730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rock Hard</td>\n",
       "      <td>An ultimatum can break your heart...   Every night lead singer, Sed Lionheart whips thousands of women into a frenzy with his voice alone. But the stage is the only place Sed feels any passion since he lost Jessica...    If you’re not willing to break all the rules...   It shattered her heart, but law student Jessica broke off her engagement to Sed, determined to be successful on her own terms. But no other man can ever hold a candle to Sed...   Then a chance meeting and tortuously close quarters lead to uncontrollable flares of passion and rediscovery of their unique penchant for public encounters. Now, in addition to the risk of mutual heartbreak every time they get together, they’re in danger of truly scandalous public exposure...</td>\n",
       "      <td>https://www.goodreads.com/book/show/9442157-rock-hard</td>\n",
       "      <td>0.179152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Half Hearts</td>\n",
       "      <td>A promise broken  Losing her family at a young age, and then broken promises from the man she’d loved all her life, Charlie McCarty rarely allows anyone to get close to her. Resolved to live her life without love and determined to become a top-notch Veterinarian, she begins her residency in Redfield. Fate, however, has a way of stepping in to change even the most obstinate set plans and forces Charlie to face her past, push the boundaries of her control and her heart to the brink of destruction.   A passion fueled desire  It started out as a celebration, a chance for Charlie to let her hair down and just let go of her firm control for just one evening, but meeting a sexy as hell cowboy—and his familiar best friend—ambush everything. With relentless determination, both cowboys set out to show her that she is everything they want to complete their lives. Charlie begins to dream, once again, for the future she thought lost to her years ago.   A Journey of the Heart  When a terrifying figure from the past steps into their fragile romance, is their love enough to overcome the horror about to be unleashed or will it leave them with hearts broken in half?</td>\n",
       "      <td>https://www.goodreads.com/book/show/10043433-half-hearts</td>\n",
       "      <td>0.178943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Coast</td>\n",
       "      <td>One life-changing summer.   One boy.  The boy.  The boy who offered me safe touches and heart-stopping smiles - smiles he shared with his son.  We filled our days with porch-step kisses,   filled our ears with laughter,   filled our hearts with love.   Deep, soul-aching, desperate love.  But love is misleading.  It's an invisible, fleeting moment.  Somewhere between false adoration and pure hatred comes an emotion, a vulnerable need, a single desire.  It lives within the ones who miss it, who crave it,   who know better than to expect it.  Love is relentless.  Even when that love turns to hate, turns to loathing,   turns to pain.   Love should heal you.   But it can also break you.   Believe me, I know...  Because I'm Becca Owens - a broken girl...  ...And he's Josh Warden - the boy who broke me.</td>\n",
       "      <td>https://www.goodreads.com/book/show/30192405-coast</td>\n",
       "      <td>0.174375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run cell\n",
    "search_engine_2(query = input_query, inverted_index = inverted_index, \n",
    "                vocabulary=vocabulary, tfidf_scores_dict=tfidfDicts,\n",
    "                df = df_dirty, k = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define a new score!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the information we have at our disposal, we have decided to explore two different approaches for our final search engine:\n",
    "1. Weighted average of the cosine_similarity, ratingValue, ratingCount and reviewCount. This is not the ideal scenario since weights are not justifiable without any data on the users search history (weights are completely based on human judgement). With more information on the user history we could continuously update the weights.\n",
    "\n",
    "\\begin{align}\n",
    "score_{new} = \\frac{CosineSimilarity \\cdot \\omega_{1} + ratingValue \\cdot \\omega_{2} + ratingCount \\cdot \\omega_{3} + reviewCount \\cdot \\omega_{4}}{max(ratingValue) + max(ratingCount) + max(reviewCount)}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "2. Normalizing the variables ratingValue, ratingCount and reviewCount upon their maximum values of the queried book ids and multiply their sum against the cosine similarity value.\n",
    "\n",
    "\\begin{align}\n",
    "score_{new} = CosineSimilarity \\cdot \\bigg(\\frac{ratingValue}{max(ratingValue)} + \\frac{ratingCount}{max(ratingCount)} + \\frac{reviewCount}{max(reviewCount)} \\bigg)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocabulary_question3, inverted_index_question3 = get_vocabulary_inverted_index(df_clean,\n",
    "                columns=['BookTitle', 'BookSeries', 'BookAuthors', 'Plot', 'PublishingDate', 'Characters'])\n",
    "\n",
    "write_json('data/inverted_index_question3.json', inverted_index_question3)\n",
    "write_json('data/vocabulary_dict_question3.json', vocabulary_question3)\n",
    "\n",
    "vectorize_tfidf(df_clean, vocabulary_question3, \n",
    "                inverted_index_question3, json_name='tfidf_question3.json',\n",
    "                columns=['BookTitle', 'BookSeries', 'BookAuthors', 'Plot', 'PublishingDate', 'Characters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def show_results_cosine_similarity_and_ratings(book_id, cosine_similarity, df):\n",
    "    \"\"\"\n",
    "    Generate a tuple with the relevant information about a book that will be displayed in the search engine, \n",
    "    the cosine similarity score and relevant quantitative information about the book (rating, reviewcount, ratingcount)\n",
    "    df: Not pre-processed data set\n",
    "    \"\"\"\n",
    "    data = df[df.BookID == book_id][['BookTitle', 'Plot', 'Url']].values.tolist()[0]\n",
    "    ratingValue = float(df[df.BookID == book_id][['RatingValue']].values[0])\n",
    "    ratingCount = float(df[df.BookID == book_id][['RatingCount']].values[0])\n",
    "    reviewCount = float(df[df.BookID == book_id][['ReviewCount']].values[0])\n",
    "    output = (cosine_similarity, ratingValue, ratingCount, reviewCount, data)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "inverted_index_question3 = read_json('data/inverted_index_question3.json')\n",
    "vocabulary_question3 = read_json_simple('data/vocabulary_dict_question3.json')\n",
    "tfidfDicts_question3 = read_json('data/tfidf_question3.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def search_engine_3(query, inverted_index, vocabulary, tfidf_scores_dict, df, k = 10,\n",
    "                    new_score='cosine_normalizer', weights=None):\n",
    "    \"\"\"\n",
    "    df: Not pre-processed data set!\n",
    "    There are currently two alterantives for the computation of the new score:\n",
    "    - cosine_normalizer: Normalize all quantitative values and multiply against cosine similiarity\n",
    "    - weighted_average: Give weights to all features based on expert judgement (provide weights as list required!!)\n",
    "    - weights: list with weights:\n",
    "        weights[0]: weight for cosine_similiarity\n",
    "        weights[1]: weight for ratingValue\n",
    "        weights[2]: weight for ratingCount\n",
    "        weights[3]: weight for reviewCount\n",
    "\n",
    "    \"\"\"\n",
    "   \n",
    "    output = pd.DataFrame(columns=['BookTitle', 'Plot', 'Url', 'Score'])\n",
    "    documents_with_query_words = query_function(query, inverted_index, vocabulary)\n",
    "    queryed_documents_tfidf = {key: value for key, value in tfidf_scores_dict.items() if key in documents_with_query_words}\n",
    "    heap_data = []\n",
    "    \n",
    "    if len(documents_with_query_words) == 0:\n",
    "        print('There are no results for the search')\n",
    "    else:\n",
    "        \n",
    "        # pre-process query\n",
    "        query = global_pre_process(query)\n",
    "\n",
    "        # vectorize query\n",
    "        vector_query = {}\n",
    "        for word in query.split(' '):\n",
    "            index = vocabulary[word]\n",
    "            vector_query[index] = 1\n",
    "\n",
    "        # Get max_ratingCount and max_reviewCount\n",
    "        ratingValue_list = []\n",
    "        ratingCount_list = []\n",
    "        reviewCount_list = []\n",
    "        ratings_df = df[df.BookID.isin(documents_with_query_words)]\n",
    "\n",
    "        max_ratingValue = max(list(map(float, df.RatingValue)))\n",
    "        max_ratingCount = max(list(map(int, df.RatingCount)))\n",
    "        max_reviewCount = max(list(map(int, df.ReviewCount)))\n",
    "\n",
    "        # Compute cosine over all intersected documents\n",
    "        for i in queryed_documents_tfidf.keys():\n",
    "            similarity = get_cosine(queryed_documents_tfidf[i], vector_query)\n",
    "            temp = show_results_cosine_similarity_and_ratings(i, similarity, df)\n",
    "            if new_score == 'weighted_average':\n",
    "                # temp[0] = cosine_similarity\n",
    "                # temp[1] = rating\n",
    "                # temp[2] = ratingCount\n",
    "                # temp[3] = reviewCount\n",
    "                # temp[4] = Relevant book information ([booktitle, plot, url])\n",
    "                score = (temp[0]*weights[0] + temp[1]*weights[1] + temp[2]*weights[2] + temp[3]*weights[3])/np.sum([max_ratingValue, \n",
    "                                                                                                                    max_ratingCount, \n",
    "                                                                                                                    max_reviewCount])\n",
    "                x = (score, temp[4])\n",
    "            elif new_score == 'cosine_normalizer':\n",
    "                # temp[0] = cosine_similarity\n",
    "                # temp[1] = rating\n",
    "                # temp[2] = ratingCount\n",
    "                # temp[3] = reviewCount\n",
    "                # temp[4] = Relevant book information ([booktitle, plot, url])\n",
    "                score = temp[0]*(temp[1]/max_ratingValue + temp[2]/max_ratingCount + temp[3]/max_reviewCount)\n",
    "                x = (score, temp[4])\n",
    "            else:\n",
    "                raise('New score method is not implemented')\n",
    "\n",
    "            if len(heap_data) < k:\n",
    "                heapq.heappush(heap_data, x)\n",
    "            else:\n",
    "                heapq.heappushpop(heap_data, x)\n",
    "\n",
    "\n",
    "        for i in range(len(heap_data)):\n",
    "            output = output.append(pd.Series([heap_data[-(i+1)][1][0], heap_data[-(i+1)][1][1], \n",
    "                                              heap_data[-(i+1)][1][2], heap_data[-(i+1)][0]], \n",
    "                                             index=output.columns), ignore_index=True) \n",
    "        output = output.sort_values(by='Score', ascending=False)\n",
    "        output = HTML(output.to_html(escape=False,\n",
    "                                     formatters=dict(column_name_with_image_links=path_to_image_html)))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "input_query = 'friends in love'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First try using the cosine_normalizer approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BookTitle</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Url</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I Don't Want To Be Friends</td>\n",
       "      <td>David  is waiting in a bar for a date who’s not going to show… bitter and alone, will he give up on the girl he loves?   After a summer spent apart  Scott  and  Haley  are back together, but something has changed between them… Will their relationship ever feel the same as before?   Madison ’s new mantra in life is: stay strong and survive senior year. She’s in love with her best friend’s boyfriend, but Scott only sees her as a friend, and her broken heart can’t take it much longer. She needs to finish college and turn the page on an impossible love story… but can she be stronger than her feelings?   Two brothers in love with the same girl.Two best friends in love with the same guy.A love triangle within a love triangle…</td>\n",
       "      <td>https://www.goodreads.com/book/show/46038462-i-don-t-want-to-be-friends</td>\n",
       "      <td>0.339369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My Best Friend's Boyfriend: A New Adult College Romance</td>\n",
       "      <td>David and Scott Williams are in love with the same girl, again.      Haley has never been happier than in her relationship with Scott. But she can no longer deny bad-boy David has gotten under her skin.      Madison has always been insecure in love. The only satisfying romances in her life come from the many books she reads. Book-boyfriends are easy to fall for, but the real world seems short of swoon-worthy heroes. And just when she thought she might’ve found one, he fell in love with her best friend…      Love and friendship mix in the Just Friends series… Meet new characters and catch up with old ones in the third book of the series.      My Best Friend’s Boyfriend is part of the Just Friends new adult college romance series.   Reading order:   Book 1 - Let’s Be Just Friends   Book 2 - Friend Zone   Book 3 - My Best Friend’s Boyfriend</td>\n",
       "      <td>https://www.goodreads.com/book/show/46038451-my-best-friend-s-boyfriend</td>\n",
       "      <td>0.269437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Friend Zone</td>\n",
       "      <td>Alice Brown  fell in love with Jack the day she moved into her freshman dorm. Problem is, she’s been stuck in the friend zone ever since. After another meaningless breakup, she’s ready to confess her feelings to Jack.   Jack Sullivan  has mistaken friendship for love once before and has vowed never to do it again. A varsity sports player, he’s determined to enjoy college with no strings attached.   Peter Wells  is Jack’s best wingman. He enjoys his popularity as team captain and when he meets Alice, he’s ready to steal her heart.   When Jack sees Alice and Peter together, jealousy hits him hard. But will he break his vow to never date a friend?   Meet new characters and catch up with old ones in the second book in the Just Friends series.   Friend Zone  is part of the  Just Friends  new adult college romance series. Reading order:  Book 1 -  Let’s Be Just Friends  Book 2 -  Friend Zone  Book 3 -  My Best Friend's Boyfriend  Book 4 -  I Don't Want To Be Friends</td>\n",
       "      <td>https://www.goodreads.com/book/show/46038439-friend-zone</td>\n",
       "      <td>0.223043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Just Friends</td>\n",
       "      <td>Love and friendship mix in the Just Friends series… the books follow the misadventures and exploits of a group of college students in Boston.    For Rose being in love with her best friend has never been easy, but now that she’s moved in with Tyler her feelings have become impossible to ignore.    Tyler has bitten more than he can chew, torn between two girls he must decide where his heart stands.    Georgiana is determined to do everything in her power to keep Tyler and Rose apart. After all, all is fair in love and war.    Alice fell in love with Jack the day she moved into her freshman dorm. Problem is, she’s been stuck in the friend zone ever since. After another meaningless breakup, she’s ready to confess her feelings to Jack.    Jack has mistaken friendship for love once before and has vowed never to do it again. A varsity sports player, he’s determined to enjoy college with no strings attached.    Peter is Jack’s best wingman. He enjoys his popularity as team captain and when he meets Alice, he’s ready to steal her heart.    David and Scott Williams are in love with the same girl, again.    Haley has never been happier than in her relationship with Scott. But she can no longer deny bad-boy David has gotten under her skin.    Madison has always been insecure in love. The only satisfying romances in her life come from the many books she reads. Book-boyfriends are easy to fall for, but the real world seems short of swoon-worthy heroes. And just when she thought she might’ve found one, he fell in love with her best friend…    Read the complete series in this amazing box set…</td>\n",
       "      <td>https://www.goodreads.com/book/show/40546422-just-friends</td>\n",
       "      <td>0.220114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angles - Part I</td>\n",
       "      <td>A compelling love story about Caralee, her best friend Teddy, and her new love interest, Sam. The intensity of Sam entering into Cara's life challenges her friendship with Teddy - which was forged long ago when they encountered a deranged gunman. Teddy will stop at nothing to protect Cara - even if it means keeping his long time business associate and once best friend far away from her.    This story is about friendship and relationship triangles, love and protection, love and understanding, and love and true love.</td>\n",
       "      <td>https://www.goodreads.com/book/show/35763791-angles</td>\n",
       "      <td>0.188829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Four Loves</td>\n",
       "      <td>The Four Loves  summarizes four kinds of human love--affection, friendship, erotic love, and the love of God. Masterful without being magisterial, this book's wise, gentle, candid reflections on the virtues and dangers of love draw on sources from Jane Austen to St. Augustine. The chapter on charity (love of God) may be the best thing Lewis ever wrote about Christianity. Consider his reflection on Augustine's teaching that one must love only God, because only God is eternal, and all earthly love will someday pass away:   Who could conceivably begin to love God on such a prudential ground--because the security (so to speak) is better? Who could even include it among the grounds for loving? Would you choose a wife or a Friend--if it comes to that, would you choose a dog--in this spirit? One must be outside the world of love, of all loves, before one thus calculates.   His description of Christianity here is no less forceful and opinionated than in  Mere Christianity  or  The Problem of Pain , but it is far less  anxious  about its reader's response--and therefore more persuasive than any of his apologetics. When he begins to describe the nature of faith, Lewis writes: \"Take it as one man's reverie, almost one man's myth. If anything in it is useful to you, use it; if anything is not, never give it a second thought.\"  --Michael Joseph Gross</td>\n",
       "      <td>https://www.goodreads.com/book/show/29938407-the-four-loves</td>\n",
       "      <td>0.185871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chicken Soup for the Teenage Soul: The Real Deal Friends: Best, Worst, Old, New, Lost, False, True and More (Chicken Soup for the Soul)</td>\n",
       "      <td>Friends. You gotta have 'em, but sometimes they drive you crazy. You love 'em, but sometimes they make you mad. They'll help you through a crisis...unless they are the crisis.   So What's the Deal?  Friends are more than just the people you hang out with. They make you laugh, they keep your secrets, they offer advice (some good, some bad), they give you a shoulder to cry on. Sometimes they move away, or betray your trust, or flake out, but mostly they are the people who are always there for you. And they know you'll be there when they need you most. Because that's what it means to be a friend.    Sometimes friendship is overwhelming, sometimes it's confusing, sometimes you feel like you don't have a friend in the world, but don't worry, it's like that for everyone. That's what the stories in this book are all about. They're from real teens, and they're about the bizarre, difficult and wonderful things that really happened to them and their friends. Put that together with weird facts, cool graphics, fun advice and quizzes designed to help you figure out what you and your friends are all about, and you've got the real deal on friendship!</td>\n",
       "      <td>https://www.goodreads.com/book/show/576087.Chicken_Soup_for_the_Teenage_Soul</td>\n",
       "      <td>0.154067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Boy & His Ribbon</td>\n",
       "      <td>“What do you do when you meet your soul mate? No wait…that’s too easy. What do you do when you meet your soul mate and have to spend a lifetime loving him in secret? I’ll tell you what you do.You lie.”   REN   Ren was eight when he learned that love doesn’t exist—that the one person who was supposed to adore him only cared how much he was worth.   His mother sold him and for two years, he lived in terror.  But then…he ran.  He thought he’d run on his own. Turned out, he took something of theirs by accident and it became the one thing he never wanted and the only thing he ever needed.    DELLA   I was young when I fell in love with him, when he switched from my world to my everything.   My parents bought him for cheap labour, just like they had with many other kids, and he had the scars to prove it.   At the start, he hated me, and I could understand why.  For years he was my worst enemy, fiercest protector, and dearest friend.  But by the end…he loved me.  The only problem was, he loved me in an entirely different way to the way I loved him.  And slowly, my secret drove us apart.</td>\n",
       "      <td>https://www.goodreads.com/book/show/37914571-the-boy-his-ribbon</td>\n",
       "      <td>0.152213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Memorizing You</td>\n",
       "      <td>Two high school boys from different walks of life: Ryan, a handsome athlete, and David, an average joe from a blue collar family, discover their desires, stealing their kisses under the cover of an old oak at night. Their love begins a secret life, hidden from their families, friends, and classmates. As their passion grows, so does the danger of their discovery. Their only hope is to create a separate world where every kiss is a treasure and every moment... memorable.   First love. Secret love. Unforgettable love.</td>\n",
       "      <td>https://www.goodreads.com/book/show/18188319-memorizing-you</td>\n",
       "      <td>0.152171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13 Minutes</td>\n",
       "      <td>They say you should keep your friends close and your enemies closer, but when you're a teenage girl, it's hard to tell them apart.   Natasha doesn't remember how she ended up in the icy water that night, but she does know this—it wasn't an accident, and she wasn't suicidal. Her two closest friends are acting strangely, and Natasha turns to Becca, the best friend she dumped years before when she got popular, to help her figure out what happened.   Natasha's sure that her friends love her. But does that mean they didn't try to kill her?</td>\n",
       "      <td>https://www.goodreads.com/book/show/26842622-13-minutes</td>\n",
       "      <td>0.148462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run cell\n",
    "search_engine_3(query = input_query, inverted_index = inverted_index_question3, \n",
    "                vocabulary=vocabulary_question3, tfidf_scores_dict=tfidfDicts_question3,\n",
    "                df = df_dirty, k = 10,\n",
    "                new_score='cosine_normalizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second try using the weighted_average approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BookTitle</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Url</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Divergent</td>\n",
       "      <td>In Beatrice Prior's dystopian Chicago world, society is divided into five factions, each dedicated to the cultivation of a particular virtue—Candor (the honest), Abnegation (the selfless), Dauntless (the brave), Amity (the peaceful), and Erudite (the intelligent). On an appointed day of every year, all sixteen-year-olds must select the faction to which they will devote the rest of their lives. For Beatrice, the decision is between staying with her family and being who she really is—she can't have both. So she makes a choice that surprises everyone, including herself.   During the highly competitive initiation that follows, Beatrice renames herself Tris and struggles alongside her fellow initiates to live out the choice they have made. Together they must undergo extreme physical tests of endurance and intense psychological simulations, some with devastating consequences. As initiation transforms them all, Tris must determine who her friends really are—and where, exactly, a romance with a sometimes fascinating, sometimes exasperating boy fits into the life she's chosen. But Tris also has a secret, one she's kept hidden from everyone because she's been warned it can mean death. And as she discovers unrest and growing conflict that threaten to unravel her seemingly perfect society, she also learns that her secret might help her save those she loves . . . or it might destroy her.</td>\n",
       "      <td>https://www.goodreads.com/book/show/13335037-divergent</td>\n",
       "      <td>0.081915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Time Traveler's Wife</td>\n",
       "      <td>A funny, often poignant tale of boy meets girl with a twist: what if one of them couldn't stop slipping in and out of time? Highly original and imaginative, this debut novel raises questions about life, love, and the effects of time on relationships.   Audrey Niffenegger’s innovative debut,  The Time Traveler’s Wife , is the story of Clare, a beautiful art student, and Henry, an adventuresome librarian, who have known each other since Clare was six and Henry was thirty-six, and were married when Clare was twenty-three and Henry thirty-one. Impossible but true, because Henry is one of the first people diagnosed with Chrono-Displacement Disorder: periodically his genetic clock resets and he finds himself misplaced in time, pulled to moments of emotional gravity in his life, past and future. His disappearances are spontaneous, his experiences unpredictable, alternately harrowing and amusing.    The Time Traveler’s Wife  depicts the effects of time travel on Henry and Clare’s marriage and their passionate love for each other as the story unfolds from both points of view. Clare and Henry attempt to live normal lives, pursuing familiar goals—steady jobs, good friends, children of their own. All of this is threatened by something they can neither prevent nor control, making their story intensely moving and entirely unforgettable.</td>\n",
       "      <td>https://www.goodreads.com/book/show/18619684-the-time-traveler-s-wife</td>\n",
       "      <td>0.044111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Charlotte's Web</td>\n",
       "      <td>This beloved book by E. B. White, author of  Stuart Little  and  The Trumpet of the Swan , is a classic of children's literature that is \"just about perfect.\" This high-quality paperback features vibrant illustrations colorized by Rosemary Wells!   Some Pig. Humble. Radiant. These are the words in Charlotte's Web, high up in Zuckerman's barn. Charlotte's spiderweb tells of her feelings for a little pig named Wilbur, who simply wants a friend. They also express the love of a girl named Fern, who saved Wilbur's life when he was born the runt of his litter.   E. B. White's Newbery Honor Book is a tender novel of friendship, love, life, and death that will continue to be enjoyed by generations to come. This edition contains newly color illustrations by Garth Williams, the acclaimed illustrator of E. B. White's  Stuart Little  and Laura Ingalls Wilder's Little House series, among many other books.</td>\n",
       "      <td>https://www.goodreads.com/book/show/24178.Charlotte_s_Web</td>\n",
       "      <td>0.039480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>City of Ashes</td>\n",
       "      <td>Also see: Alternate Cover Editions for this ISBN [ACE]     \\nACE #1\\n   Clary Fray just wishes that her life would go back to normal. But what's normal when you're a demon-slaying Shadowhunter, your mother is in a magically induced coma, and you can suddenly see Downworlders like werewolves, vampires, and faeries? If Clary left the world of the Shadowhunters behind, it would mean more time with her best friend, Simon, who's becoming more than a friend. But the Shadowhunting world isn't ready to let her go — especially her handsome, infuriating, newfound brother, Jace. And Clary's only chance to help her mother is to track down rogue Shadowhunter Valentine, who is probably insane, certainly evil — and also her father.   To complicate matters, someone in New York City is murdering Downworlder children. Is Valentine behind the killings — and if he is, what is he trying to do? When the second of the Mortal Instruments, the Soul-Sword, is stolen, the terrifying Inquisitor arrives to investigate and zooms right in on Jace. How can Clary stop Valentine if Jace is willing to betray everything he believes in to help their father?   In this breathtaking sequel to  City of Bones , Cassandra Clare lures her readers back into the dark grip of New York City's Downworld, where love is never safe and power becomes the deadliest temptation.</td>\n",
       "      <td>https://www.goodreads.com/book/show/1582996.City_of_Ashes</td>\n",
       "      <td>0.021099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Goldfinch</td>\n",
       "      <td>It begins with a boy. Theo Decker, a thirteen-year-old New Yorker, miraculously survives an accident that kills his mother. Abandoned by his father, Theo is taken in by the family of a wealthy friend. Bewildered by his strange new home on Park Avenue, disturbed by schoolmates who don't know how to talk to him, and tormented above all by his unbearable longing for his mother, he clings to one thing that reminds him of her: a small, mysteriously captivating painting that ultimately draws Theo into the underworld of art.   As an adult, Theo moves silkily between the drawing rooms of the rich and the dusty labyrinth of an antiques store where he works. He is alienated and in love-and at the center of a narrowing, ever more dangerous circle.   The Goldfinch  combines vivid characters, mesmerizing language, and suspense, while plumbing with a philosopher's calm the deepest mysteries of love, identity, and art. It is an old-fashioned story of loss and obsession, survival and self-invention, and the ruthless machinations of fate.</td>\n",
       "      <td>https://www.goodreads.com/book/show/17333223-the-goldfinch</td>\n",
       "      <td>0.020767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>If I Stay</td>\n",
       "      <td>Librarian note: an alternate cover for this edition can be found here.   Just listen, Adam says with a voice that sounds like shrapnel.I open my eyes wide now.I sit up as much as I can.And I listen.Stay, he says.   Choices. Seventeen-year-old Mia is faced with some tough ones: Stay true to her first love—music—even if it means losing her boyfriend and leaving her family and friends behind?   Then one February morning Mia goes for a drive with her family, and in an instant, everything changes. Suddenly, all the choices are gone, except one. And it's the only one that matters.   If I Stay  is a heartachingly beautiful book about the power of love, the true meaning of family, and the choices we all make.</td>\n",
       "      <td>https://www.goodreads.com/book/show/4374400-if-i-stay</td>\n",
       "      <td>0.020220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Matched</td>\n",
       "      <td>In the Society, officials decide. Who you love. Where you work. When you die.   Cassia has always trusted their choices. It’s hardly any price to pay for a long life, the perfect job, the ideal mate. So when her best friend appears on the Matching screen, Cassia knows with complete certainty that he is the one…until she sees another face flash for an instant before the screen fades to black. Now Cassia is faced with impossible choices: between Xander and Ky, between the only life she’s known and a path no one else has ever dared follow—between perfection and passion.   Matched  is a story for right now and storytelling with the resonance of a classic.</td>\n",
       "      <td>https://www.goodreads.com/book/show/7735333-matched</td>\n",
       "      <td>0.018530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Sisterhood of the Traveling Pants</td>\n",
       "      <td>Carmen got the jeans at a thrift shop. They didn’t look all that great: they were worn, dirty, and speckled with bleach. On the night before she and her friends part for the summer, Carmen decides to toss them.    But Tibby says they’re great. She'd love to have them. Lena and Bridget also think they’re fabulous. Lena decides that they should all try them on. Whoever they fit best will get them.    Nobody knows why, but the pants fit everyone perfectly. Even Carmen (who never thinks she looks good in anything) thinks she looks good in the pants. Over a few bags of cheese puffs, they decide to form a sisterhood and take the vow of the Sisterhood of the Traveling Pants . . . the next morning, they say good-bye.    And then the journey of the pants — and the most memorable summer of their lives — begins.</td>\n",
       "      <td>https://www.goodreads.com/book/show/452306.The_Sisterhood_of_the_Traveling_Pants</td>\n",
       "      <td>0.017326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hush, Hush</td>\n",
       "      <td>A SACRED OATHA FALLEN ANGELA FORBIDDEN LOVE   Romance was not part of Nora Grey's plan. She's never been particularly attracted to the boys at her school, no matter how hard her best friend, Vee, pushes them at her. Not until Patch comes along. With his easy smile and eyes that seem to see inside her, Patch draws Nora to him against her better judgment.   But after a series of terrifying encounters, Nora's not sure whom to trust. Patch seems to be everywhere she is and seems to know more about her than her closest friends. She can't decide whether she should fall into his arms or run and hide. And when she tries to seek some answers, she finds herself near a truth that is way more unsettling than anything Patch makes her feel.   For she is right in the middle of an ancient battle between the immortal and those that have fallen - and, when it comes to choosing sides, the wrong choice will cost Nora her life.</td>\n",
       "      <td>https://www.goodreads.com/book/show/6339664-hush-hush</td>\n",
       "      <td>0.016234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vampire Academy</td>\n",
       "      <td>ONLY A TRUE BEST FRIEND CAN PROTECT YOU FROM YOUR IMMORTAL ENEMIES...   Lissa Dragomir is a Moroi princess: a mortal vampire with a rare gift for harnessing the earth's magic. She must be protected at all times from Strigoi; the fiercest vampires - the ones who never die. The powerful blend of human and vampire blood that flows through Rose Hathaway, Lissa's best friend, makes her a dhampir. Rose is dedicated to a dangerous life of protecting Lissa from the Strigoi, who are hell-bent on making Lissa one of them.   After two years of freedom, Rose and Lissa are caught and dragged back to St. Vladimir's Academy, a school for vampire royalty and their guardians-to-be, hidden in the deep forests of Montana. But inside the iron gates, life is even more fraught with danger... and the Strigoi are always close by.   Rose and Lissa must navigate their dangerous world, confront the temptations of forbidden love, and never once let their guard down, lest the evil undead make Lissa one of them forever...</td>\n",
       "      <td>https://www.goodreads.com/book/show/345627.Vampire_Academy</td>\n",
       "      <td>0.015506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run cell\n",
    "search_engine_3(query = input_query, inverted_index = inverted_index_question3, \n",
    "                vocabulary=vocabulary_question3, tfidf_scores_dict=tfidfDicts_question3,\n",
    "                df = df_dirty, k = 10,\n",
    "                new_score='weighted_average', weights=[0.5, 0.2, 0.2, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make a nice visualization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "def get_book_series(df, num_series=20, series_to_include=['Harry Potter']):\n",
    "    \"\"\" \n",
    "    Get first num_series Book Series based on the order of apperance (also including series in the list series_to_include)\n",
    "    df: Not pre-processed data set!\n",
    "    \"\"\"\n",
    "    bookSeries = {}\n",
    "    for index, row in df.iterrows():\n",
    "        d_id = row['BookID']\n",
    "        book_data = row\n",
    "        clean_series = re.sub(r'[^a-zA-Z0-9]', ' ', book_data['BookSeries']).split()\n",
    "        series_name = re.sub(r'[^a-zA-Z]', ' ', book_data['BookSeries']).rstrip().lstrip()\n",
    "        # If the book is part of a series and the series is one single book\n",
    "        if (series_name != '') & (len([i for i in clean_series if bool(re.match(r'\\d+', i))]) == 1):\n",
    "            if series_name not in bookSeries:\n",
    "                # Make sure we only take the first 20 series\n",
    "                if (len(bookSeries.keys()) < num_series) | (series_name in series_to_include):\n",
    "                    split_date = re.findall(r'\\d+', book_data['PublishingDate'])\n",
    "                    year = [i for i in split_date if len(i) == 4][0]\n",
    "                    bookSeries[series_name] = [[' '.join(clean_series), year, book_data['NumberofPages'], book_data['Url']]]\n",
    "            else:                \n",
    "                split_date = re.findall(r'\\d+', book_data['PublishingDate'])\n",
    "                try:\n",
    "                    year = [i for i in split_date if len(i) == 4][0]\n",
    "                except:\n",
    "                    year = book_data[8]\n",
    "                bookSeries[series_name].append([' '.join(clean_series), year, book_data['NumberofPages'], book_data['Url']])\n",
    "\n",
    "    return bookSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell\n",
    "book_series = get_book_series(df_dirty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce5b501e182b4ec28c248658ef16fece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='series_name', options=('The Hunger Games', 'From  A Journal of Lov…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run cell\n",
    "from ipywidgets import interact, Dropdown\n",
    "\n",
    "dropdown_bookSeries = Dropdown(options = list(book_series.keys()))\n",
    "\n",
    "def plot_series(series_name, bookSeries_dict = book_series):\n",
    "    publish_years = [i[1] for i in bookSeries_dict[series_name]]\n",
    "    pages = [i[2] for i in bookSeries_dict[series_name]]\n",
    "    df = pd.DataFrame(columns=['Year', 'Pages'])\n",
    "    df['Year'] = [int(i) for i in publish_years]\n",
    "    df['Pages'] = [int(i) for i in pages]\n",
    "    df = df.sort_values(by='Year', ascending=True)\n",
    "    df['Years Since Publishment'] = df.Year - df.Year.min()\n",
    "    df['Pages of Book Series'] = df.Pages.cumsum()\n",
    "    df.plot(x = 'Years Since Publishment', y = 'Pages of Book Series', title = series_name,\n",
    "            figsize=(12,8))\n",
    "    print(df)\n",
    "    \n",
    "@interact(series_name = dropdown_bookSeries)\n",
    "def dropdown_series(series_name):\n",
    "    plot_series(series_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Algorithmic Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a recursive program that, given a string, computes the length of the subsequence of maximum length that is in alphabetical order. Try some examples. Are the examples of short strings correct? Can you find examples that your algorithm does not terminate in reasonable time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_function_terminates_n(X, n):\n",
    "    \"\"\"\n",
    "    Compute the longest subsequence in alphabetical order that terminates at position n of the string X\n",
    "    X: string\n",
    "    n: len string    \n",
    "    \"\"\"\n",
    "    if n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 1 + max([recursive_function_terminates_n(X[:-i], len(X[:-i])) for i in range(1, n) if X[n-1] > X[-(i+1)]], \n",
    "                       default=0)\n",
    "    \n",
    "def recursive_function(X):\n",
    "    \"\"\"\n",
    "    Function to loop over all letter in the word X and compute the real longest subsequence in \n",
    "    alphabteical order of the whole string\n",
    "    \"\"\"\n",
    "    len_list = []\n",
    "    for i in range(len(X)):\n",
    "        len_list.append(recursive_function_terminates_n(X[:i+1], len(X[:i+1])))\n",
    "    return max(len_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a program that computes the length of the subsequence of maximum length, using dynamic programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_function(X, print_max_len = False): \n",
    "    \"\"\" \n",
    "    X is a string\n",
    "    \"\"\"\n",
    "    m = len(X)\n",
    "\n",
    "    L = [X[0]]\n",
    "\n",
    "    # We going letter by letter adding the new letter to all possible alphabetically ordered strings\n",
    "    for i in range(1, m):\n",
    "        L =  L + [X[i]] + [j + X[i] for j in L if j[-1] < X[i]]\n",
    "        \n",
    "    # Conditions t print all the max length strings or not\n",
    "    L_len = [len(j) for j in L]\n",
    "    if print_max_len:\n",
    "        L_max = [j for j in L if len(j) == max(L_len)]\n",
    "        return max(L_len), L_max\n",
    "    else:\n",
    "        return max(L_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick proof that both functions return the same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import string\n",
    "\n",
    "def get_string(n):\n",
    "    \n",
    "    return  ''.join(random.choice(string.ascii_uppercase) for _ in range(n))\n",
    "\n",
    "X = get_string(25)\n",
    "\n",
    "res_1 = recursive_function(X)\n",
    "res_2 = dynamic_function(X)\n",
    "assert res_1 == res_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prove that the formula for X[i] given above is correct.   (CORRECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are given the following algorithm to obtain the length of the longest subsequence in alphabetical order:\n",
    "\n",
    "\\begin{align}\n",
    "X[i] = 1 + max(X[j]; j = 0, ..., i-1, \\text{ s.t. } S[j]<S[i])\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "X[i] = 1, \\text{ if there does not exist such as } j\n",
    "\\end{align}\n",
    "\n",
    "**Proof**\n",
    "\n",
    "We will demonstrate this by breaking the problem down into smaller assumptions that logically guarantee the final conclusion.\n",
    "\n",
    "1. We can easily state that X[i] <= X[j] for every j > i. This is easy to prove since an additional letter can only make the subsequence longer.\n",
    "2. It is important to notice in the previous statement that we are using the <= sign and not the strict < since there are some conditions that need to be fulfilled for the strict < to occur.\n",
    "3. In particular, and considering the previous, we can be even more specific when expressing X[i] in terms of X[j] (please beer for a moment since the previous is only partially true):\n",
    "\n",
    "\\begin{align}\n",
    "X[i] = X[j] + 1 \\text{ if } S[j]>S[i] \n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "X[i] = X[j] \\text{ if } S[j]<S[i]\n",
    "\\end{align}\n",
    "\n",
    "4. The issue with the previous statement is that we are only considering one single potential longest string, when in general we are interested in all possible string combinations (from 1 until j). In order to solve this we will look into the longest subsequence in alphabetical order of the X[j] string. This is preciselly what is being done in the term max(X[j]; j = 0, ..., i-1, s.t. S[j]<S[i]) (we loop over all X[j] values such that S[j]<S[i] and compute the longest subsequence in alphabetical order from these X[j]'s).\n",
    "5. Finally, if there is no S[j]<S[i], meaning that the string is of length 1, or that non of the letters are in alphabetical order, of course X[i] = 1.\n",
    "\n",
    "**Q.E.D.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
